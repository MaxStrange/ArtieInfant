# This configuration file contains all the same configurations as the
# Thesis experiment, but the values are suitable for unittesting quickly.

# The Synthesizer section contains all the configuration options for the
# Articulatory Synthesis portions of the experiment.
[synthesizer]
    # The number of ms of all phonemes we will try to learn.
    phoneme-durations-ms = 300

    # When during the articulation the controller may change muscle activations.
    articulation-time-points-ms = 0 150 300

    # Number of steps to take before training. Important because you should fill the memory buffer with some items before sampling from them.
    actor-warmup-steps = 1

    # Ditto
    critic-warmup-steps = 1

    # Standard RL gamma value
    discount-factor = 0.99

    # The number of steps to train the agent during pretraining (just trying to get it to vocalize)
    pretraining-steps = 10

# The Preprocessing section contains all the configuration options for
# the preprocessing pipeline. This pipeline attempts to take completely raw
# WAV files and get them into shape for the RL and VAE algorithms.
[preprocessing]
    # Root of all the audio that you want to preprocess
    root = "/media/max/seagate8TB/thesis_audio/gold_data_do_not_modify"

    # Folder where all the preprocessed audio will be dumped
    destination = "/media/max/seagate8TB/thesis_audio/preprocessed_gold_data"

    # Number of worker processes to use to preprocess
    nworkers = 4

    # Resample the audio to this sample rate.
    sample_rate_hz = 32000.0

    # For each file that we find, we preprocess it only with this probability. Useful for debugging/testing.
    fraction_to_preprocess = 0.10

    # Number of channels to resample into. Only mono makes any sense for this experiment.
    nchannels = 1

    # Bytewidth of each sample to resample to.
    bytewidth = 2

    # Seconds each piece of audio should be diced down to (before preprocessing each one).
    dice_to_seconds = 30.0

    # -- Baby Detector --
    # Each of the following parameters must match exactly the values you used to train the model.

    # The sampling rate that the baby detector expects the data to be in.
    baby_detector_sample_rate_hz = 22050.0

    # The byte-width the baby detector expects the data to be in.
    baby_detector_sample_width_bytes = 2

    # The number of ms of audio data to feed into the baby detector at a time.
    baby_detector_ms = 300.0

    # The type of model to create for the baby detector. Allowable options are ['fft', 'spec'] for an FFT model or a Spectrogram model.
    baby_detector_model_type = "fft"

    # Only used if 'baby_detector_model_type' is "spec". The ms per window.
    baby_detector_window_length_ms = 30.0

    # Only used if 'baby_detector_model_type' is "spec". The fraction of each window to overlap.
    baby_detector_overlap = 0.125

    # Only used if 'baby_detector_model_type' is "spec". The shape of the spectrogram data to expect.
    baby_detector_spectrogram_shape = [1, 2]

    # Probability of observing a transition from baby sound to no baby sound in 'baby_detector_ms' segment of data.
    baby_detector_p_yes_to_no = 0.2

    # Probability of observing a transition from no baby sound to baby sound in 'baby_detector_ms' segment of data.
    baby_detector_p_no_to_yes = 0.1

    # The P(reality=1 | model output=1)
    baby_detector_positive_predictive_value = 0.5

    # The P(reality=1 | model output=0)
    baby_detector_negative_predictive_value = 0.5

    # The typical length of a baby event in seconds
    baby_detector_event_length_s = 1.5

    # The raw probability of baby noise being present in any given 'baby_detector_ms' segment of data.
    baby_detector_raw_yes = 0.3

    # -- Language Detector --
    # Each of the following parameters must match exactly the values you used to train the model.

    # The sampling rate that the language detector expects the data to be in.
    language_detector_sample_rate_hz = 22050.0

    # The byte-width the language detector expects the data to be in.
    language_detector_sample_width_bytes = 2

    # The number of ms of audio data to feed into the language detector at a time.
    language_detector_ms = 300.0

    # The type of model to create for the language detector. Allowable options are ['fft', 'spec'] for an FFT model or a Spectrogram model.
    language_detector_model_type = "fft"

    # Only used if 'language_detector_model_type' is "spec". The ms per window.
    language_detector_window_length_ms = 30.0

    # Only used if 'language_detector_model_type' is "spec". The fraction of each window to overlap.
    language_detector_overlap = 0.125

    # Only used if 'language_detector_model_type' is "spec". The shape of the spectrogram data to expect.
    language_detector_spectrogram_shape = [1, 2]

    # Probability of observing a transition from Chinese to not Chinese in 'language_detector_ms' segment of data.
    language_detector_p_yes_to_no = 0.2

    # Probability of observing a transition from no Chinese to Chinese in 'language_detector_ms' segment of data.
    language_detector_p_no_to_yes = 0.1

    # The P(reality=1 | model output=1)
    language_detector_positive_predictive_value = 0.5

    # The P(reality=1 | model output=0)
    language_detector_negative_predictive_value = 0.5

    # The typical length of a Chinese event in seconds
    language_detector_event_length_s = 1.5

    # The raw probability of Chinese being present in any given 'language_detector_ms' segment of data.
    language_detector_raw_yes = 0.3

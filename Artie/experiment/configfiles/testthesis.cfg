# This configuration file contains all the same configurations as the
# Thesis experiment, but the values are suitable for unittesting quickly.

# The Synthesizer section contains all the configuration options for the
# Articulatory Synthesis portions of the experiment.
[synthesizer]
    # The number of ms of all phonemes we will try to learn.
    phoneme-durations-ms = 500

    # When during the articulation the controller may change muscle activations.
    articulation-time-points-ms = 0 100 250 500

    # These are the [min, max, min, max, min, max] values for each articulator
    # for each time point.
    ####### THESE VALUES CREATE A KNOWN SOUND #######
    #allowed-articulator-values = {
    #    Lungs:                      [0.2  0.2   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Interarytenoid:             [0.5  0.5   0.5  0.5   0.5  0.5   0.5  0.5],
    #    Cricothyroid:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Vocalis:                    [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Thyroarytenoid:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    PosteriorCricoarytenoid:    [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LateralCricoarytenoid:      [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Stylohyoid:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Thyropharyngeus:            [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LowerConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    MiddleConstrictor:          [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    UpperConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Sphincter:                  [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Hyoglossus:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Styloglossus:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Genioglossus:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    UpperTongue:                [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LowerTongue:                [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    TransverseTongue:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    VerticalTongue:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Risorius:                   [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    OrbicularisOris:            [0.0  0.0   0.0  0.0   0.2  0.2   0.0  0.0],
    #    LevatorPalatini:            [1.0  1.0   1.0  1.0   1.0  1.0   1.0  1.0],
    #    TensorPalatini:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Masseter:                   [0.0  0.0   0.0  0.0   0.7  0.7   0.0  0.0],
    #    Mylohyoid:                  [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LateralPterygoid:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Buccinator:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    }

    ##### This seems to make a loud noise #######
    #allowed-articulator-values = {
    #    Lungs:                      [0.0  0.2   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Stick this at 0.5 for now # Don't know what it does
    #    Interarytenoid:             [0.5  0.5   0.5  0.5   0.5  0.5   0.5  0.5],
    #    # This muscle changes the pitch (frequency)
    #    Cricothyroid:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # This and thyroarytenoid work together to do something I guess
    #    Vocalis:                    [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Thyroarytenoid:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # These two have to do with breathing maybe?
    #    PosteriorCricoarytenoid:    [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LateralCricoarytenoid:      [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Responsible for swallowing
    #    Stylohyoid:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Important in swallowing food - as well as the constrictors
    #    Thyropharyngeus:            [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LowerConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    MiddleConstrictor:          [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    UpperConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Who knows?
    #    Sphincter:                  [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Helps with tongue (all glossus muscles)
    #    Hyoglossus:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Styloglossus:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Genioglossus:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Tongue!
    #    UpperTongue:                [0.0  0.0   0.0  0.8   0.0  0.8   0.0  0.0],
    #    LowerTongue:                [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    TransverseTongue:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    VerticalTongue:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Helpful for smiling
    #    Risorius:                   [0.0  0.0   0.7  0.9   0.2  0.5   0.0  0.0],
    #    # Lip-puckering
    #    OrbicularisOris:            [0.0  0.0   0.0  0.0   0.2  0.5   0.0  0.0],
    #    # Soft-palate (responsible for nasalisation) - same with tensor palatini
    #    LevatorPalatini:            [1.0  1.0   1.0  1.0   1.0  1.0   1.0  1.0],
    #    TensorPalatini:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Helps to open/close the jaw
    #    Masseter:                   [0.0  0.0   0.0  0.0   0.0  1.0   0.0  0.0],
    #    # Important for moving the bottom of the mouth and the tongue
    #    Mylohyoid:                  [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Helps to open/close the jaw
    #    LateralPterygoid:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    # Helpful in puckering and whistling
    #    Buccinator:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    }

    allowed-articulator-values = {
        Lungs:                      [0.0  0.2   0.0  0.0   0.0  0.0   0.0  0.0],
        # Stick this at 0.5 for now # Don't know what it does
        Interarytenoid:             [0.5  0.5   0.5  0.5   0.5  0.5   0.5  0.5],
        # This muscle changes the pitch (frequency)
        Cricothyroid:               [-0.5  0.5   -0.5  0.5   -0.5  0.5   0.0  0.0],
        # This and thyroarytenoid work together to do something I guess
        Vocalis:                    [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        Thyroarytenoid:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        # These two have to do with breathing maybe?
        PosteriorCricoarytenoid:    [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        LateralCricoarytenoid:      [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        # Responsible for swallowing
        Stylohyoid:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        # Important in swallowing food - as well as the constrictors
        Thyropharyngeus:            [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        LowerConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        MiddleConstrictor:          [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        UpperConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        # Who knows?
        Sphincter:                  [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        # Helps with tongue (all glossus muscles)
        Hyoglossus:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        Styloglossus:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        Genioglossus:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
        # Tongue!
        UpperTongue:                [-0.5  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        LowerTongue:                [-0.5  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        TransverseTongue:           [-0.5  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        VerticalTongue:             [-0.5  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        # Helpful for smiling
        Risorius:                   [-0.5  1.0   -0.5  1.0   0.0  1.0   0.0  1.0],
        # Lip-puckering
        OrbicularisOris:            [0.0  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        # Soft-palate (responsible for nasalisation) - same with tensor palatini
        LevatorPalatini:            [0.0  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        TensorPalatini:             [0.0  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        # Helps to open/close the jaw
        Masseter:                   [0.0  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        # Important for moving the bottom of the mouth and the tongue
        Mylohyoid:                  [0.0  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        # Helps to open/close the jaw
        LateralPterygoid:           [0.0  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        # Helpful in puckering and whistling
        Buccinator:                 [0.0  1.0   0.0  1.0   0.0  1.0   0.0  1.0],
        }

    # The number of agents to create as part of the genetic algorithm for phase 0 (loudness training)
    nagents-phase0 = 80

    # The number of workers to use in parallel for training the genetic algorithm in phase 0
    nworkers-phase0 = 8

    # The number of generations of agents to simulate for the genetic algorithm in phase 0. Can be None.
    # Either this or fitness-target-phase0 must be specified, however.
    niterations-phase0 = 10

    # The target fitness value to converge on in the genetic algorithm in phase 0. Can be None.
    # Either this or niterations-phase0 must be specified, however.
    fitness-target-phase0 = None

    # The top x percent of each generation is chosen for breeding in the genetic algorithm
    fraction-of-generation-to-select-phase0 = 0.1

    # X percent of each generation is subject to mutation.
    fraction-of-generation-to-mutate-phase0 = 0.05

# The autoencoder section contains all the configuration options for the
# variational autoencoder portions of the experiment.
[autoencoder]
    # The input shape that the encoder layer is expecting. This will depend on the ms per spectrogram,
    # the overlap, and the sampling frequency of the audio.
    input_shape = 241 20 1

    # The dimensionality of the embedding space
    nembedding_dims = 2

    # The Keras Optimizer to use for the autoencoder
    optimizer = adadelta

    # The loss function to use for the autoencoder. See the VAE for available values.
    loss = mse

    # The root of the preprocessed data directory. We will grab data from here and feed it into the autoencoder to train it.
    preprocessed_data_root = /media/max/seagate8TB/thesis_audio/test_spectrogram_images/hundred_thousand

    # The number of spectrograms to batch at a time
    batchsize = 32

    # The number of workers to use to train
    nworkers = 4

    # The number of epochs to train. Note that we define how long an epoch is manually.
    nepochs = 1

    # The number of steps per epoch. (Should be num_samples / batchsize)
    steps_per_epoch = 2000

    # The path to save/load the autoencoder weights. A timestamp and .h5 extension will be appended to this base name.
    weights_path = /home/max/repos/ArtieInfant/Artie/models/vae/test

    # Whether or not we should visualize the autoencoder's training
    visualize = False

# The Preprocessing section contains all the configuration options for
# the preprocessing pipeline. This pipeline attempts to take completely raw
# WAV files and get them into shape for the RL and VAE algorithms.
[preprocessing]
    # Root of all the audio that you want to preprocess
    root = /media/max/seagate8TB/thesis_audio/gold_data_do_not_modify

    # Folder where all the preprocessed audio will be dumped
    destination = /media/max/seagate8TB/thesis_audio/preprocessed_gold_data

    # Number of worker processes to use to preprocess
    nworkers = 4

    # Resample the audio to this sample rate.
    sample_rate_hz = 32000.0

    # For each file that we find, we preprocess it only with this probability. Useful for debugging/testing.
    fraction_to_preprocess = 0.01

    # Number of channels to resample into. Only mono makes any sense for this experiment.
    nchannels = 1

    # Bytewidth of each sample to resample to.
    bytewidth = 2

    # Seconds each piece of audio should be diced down to (before preprocessing each one).
    dice_to_seconds = 600

    # -- Baby Detector --
    # Each of the following parameters must match exactly the values you used to train the model.

    # The sampling rate that the baby detector expects the data to be in.
    baby_detector_sample_rate_hz = 22050.0

    # The byte-width the baby detector expects the data to be in.
    baby_detector_sample_width_bytes = 2

    # The number of ms of audio data to feed into the baby detector at a time.
    baby_detector_ms = 300.0

    # The type of model to create for the baby detector. Allowable options are ['fft', 'spec'] for an FFT model or a Spectrogram model.
    baby_detector_model_type = fft

    # Only used if 'baby_detector_model_type' is "spec". The ms per window.
    baby_detector_window_length_ms = 30.0

    # Only used if 'baby_detector_model_type' is "spec". The fraction of each window to overlap.
    baby_detector_overlap = 0.125

    # Only used if 'baby_detector_model_type' is "spec". The shape of the spectrogram data to expect.
    baby_detector_spectrogram_shape = [1, 2]

    # Probability of observing a transition from baby sound to no baby sound in 'baby_detector_ms' segment of data.
    baby_detector_p_yes_to_no = 0.2

    # Probability of observing a transition from no baby sound to baby sound in 'baby_detector_ms' segment of data.
    baby_detector_p_no_to_yes = 0.1

    # The P(reality=1 | model output=1)
    baby_detector_positive_predictive_value = 0.5

    # The P(reality=1 | model output=0)
    baby_detector_negative_predictive_value = 0.5

    # The typical length of a baby event in seconds
    baby_detector_event_length_s = 1.5

    # The raw probability of baby noise being present in any given 'baby_detector_ms' segment of data.
    baby_detector_raw_yes = 0.3

    # -- Language Detector --
    # Each of the following parameters must match exactly the values you used to train the model.

    # The sampling rate that the language detector expects the data to be in.
    language_detector_sample_rate_hz = 22050.0

    # The byte-width the language detector expects the data to be in.
    language_detector_sample_width_bytes = 2

    # The number of ms of audio data to feed into the language detector at a time.
    language_detector_ms = 300.0

    # The type of model to create for the language detector. Allowable options are ['fft', 'spec'] for an FFT model or a Spectrogram model.
    language_detector_model_type = fft

    # Only used if 'language_detector_model_type' is "spec". The ms per window.
    language_detector_window_length_ms = 30.0

    # Only used if 'language_detector_model_type' is "spec". The fraction of each window to overlap.
    language_detector_overlap = 0.125

    # Only used if 'language_detector_model_type' is "spec". The shape of the spectrogram data to expect.
    language_detector_spectrogram_shape = [1, 2]

    # Probability of observing a transition from Chinese to not Chinese in 'language_detector_ms' segment of data.
    language_detector_p_yes_to_no = 0.2

    # Probability of observing a transition from no Chinese to Chinese in 'language_detector_ms' segment of data.
    language_detector_p_no_to_yes = 0.1

    # The P(reality=1 | model output=1)
    language_detector_positive_predictive_value = 0.5

    # The P(reality=1 | model output=0)
    language_detector_negative_predictive_value = 0.5

    # The typical length of a Chinese event in seconds
    language_detector_event_length_s = 1.5

    # The raw probability of Chinese being present in any given 'language_detector_ms' segment of data.
    language_detector_raw_yes = 0.3

    # -- Spectrograms --

    # Where to put the images of the spectrograms
    images_destination = /media/max/seagate8TB/thesis_audio/filterbank_images/all/pointless_subdir

    # Use a filterbank?
    use_filterbank = False

    # Sample rate (in Hz) to resample to before creating the spectrograms
    spectrogram_sample_rate_hz = 16000.0

    # Seconds per spectrogram (this should almost certainly be the same value as phoneme-durations-ms)
    seconds_per_spectrogram = 0.5

    # Length (in seconds) of each spectrogram window
    spectrogram_window_length_s = 0.03

    # Fraction of overlap between each spectrogram window
    spectrogram_window_overlap = 0.2

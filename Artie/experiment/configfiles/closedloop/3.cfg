[experiment]
    # Name of the experiment: If this is a genetic experiment for phase 2, you MUST
    # also make sure the mimicry-targets exist in the folder-to-save-wavs. Use the
    # make_sound_from_spec_name script. The audio files should have been saved as part of
    # preprocessing, but for the 0.5 second ones, I do not think this was done.
    # This means you should also verify that the spectrogram of the audio file you create
    # with the make_sound_from_spec_name script is the same as the one you are loading
    # in mimicry-targets.
    name = closedloop-0.3s-tps0.0-100pop-12gen-euclid-nox

    # A directory where results will be saved will be created from joining this root directory to the name of the experiment
    save_root = /home/max/Dropbox/thesis/results/real

    # Random seed for the experiment (must be 32-bit unsigned integer)
    random-seed = 235238

# The Synthesizer section contains all the configuration options for the
# Articulatory Synthesis portions of the experiment.
[synthesizer]
    # The number of ms of all phonemes we will try to learn.
    phoneme-durations-ms = 300

    # When during the articulation the controller may change muscle activations.
    articulation-time-points-ms = 0

    # These are the [min, max, min, max] values for each articulator
    # for each time point. See synthesizer.py for which of these are in which
    # articulator group.
    # This matrix specifies the total limits. If annealing is turned on,
    # we zero out portions of the matrix during specific portions of phase 1
    # training. Regardless of whether annealing is on or off for phase 0,
    # we zero out all but the laryngeal group during phase 0.
    allowed-articulator-values = {
        Lungs:                      [0.2  0.2],
        Interarytenoid:             [0.5  0.5],
        Cricothyroid:               [-1.0  1.0],
        Vocalis:                    [-1.0  1.0],
        Thyroarytenoid:             [-1.0  1.0],
        PosteriorCricoarytenoid:    [0.0  0.0],
        LateralCricoarytenoid:      [0.0  0.0],
        Stylohyoid:                 [0.0  0.0],
        Thyropharyngeus:            [0.0  0.0],
        LowerConstrictor:           [0.0  0.0],
        MiddleConstrictor:          [0.0  0.0],
        UpperConstrictor:           [0.0  0.0],
        Sphincter:                  [0.0  0.0],
        Hyoglossus:                 [0.0  0.0],
        Styloglossus:               [0.0  0.5],
        Genioglossus:               [0.0  0.0],
        UpperTongue:                [-1.0  0.0],
        LowerTongue:                [-1.0  0.0],
        TransverseTongue:           [0.0  0.0],
        VerticalTongue:             [0.0  0.0],
        Risorius:                   [0.0  0.0],
        OrbicularisOris:            [0.5  1.0],
        LevatorPalatini:            [-1.0  1.0],
        TensorPalatini:             [-1.0  1.0],
        Masseter:                   [-0.5  0.0],
        Mylohyoid:                  [-1.0  1.0],
        LateralPterygoid:           [0.0  0.0],
        Buccinator:                 [0.0  0.0],
        }

    # The number of agents to create as part of the genetic algorithm for phase 0 (loudness training)
    nagents-phase0 = 100

    # The number of agents to create as part of the genetic algorithm for phase 1 (mimicking)
    nagents-phase1 = 100

    # The number of workers to use in parallel for training the genetic algorithm in phase 0
    nworkers-phase0 = 12

    # The number of workers to use in parallel for training the genetic algorithm in phase 1
    nworkers-phase1 = 12

    # The number of generations of agents to simulate for the genetic algorithm in phase 0. Can be None.
    # Either this or fitness-target-phase0 must be specified, however.
    niterations-phase0 = 16

    # The number of generations of agents to simulate for the genetic algorithm in phase 1. Can be None.
    # Either this or fitness-target-phase1 must be specified, however.
    # If anneal-during-phase1 is True, this can be a list, in which case, it should contain the number
    # of iterations for each group of articulators. If annealing is turned on and this is not a list,
    # we will do this many iterations per anneal.
    # Jaw, Nasal, Lingual support, Lingual main, Labial
    niterations-phase1 = 12 12 12 12 12

    # The target fitness value to converge on in the genetic algorithm in phase 0. Can be None.
    # Either this or niterations-phase0 must be specified, however.
    fitness-target-phase0 = None

    # The target fitness value to converge on in the genetic algorithm in phase 1. Can be None.
    # Either this or niterations-phase1 must be specified, however.
    # If anneal-during-phase1 is True, this can be a list, in which case, it should contain the fitness targets
    # for each group of articulators. If annealing is turned on and this is not a list,
    # we will use this for each articulator group.
    fitness-target-phase1 = None

    # The top x percent of each generation is chosen for breeding in the genetic algorithm
    fraction-of-generation-to-select-phase0 = 0.5

    # The top x percent of each generation is chosen for breeding in the genetic algorithm
    fraction-of-generation-to-select-phase1 = 0.5

    # X percent of each generation is subject to mutation.
    fraction-of-generation-to-mutate-phase0 = 0.10

    # X percent of each generation is subject to mutation.
    fraction-of-generation-to-mutate-phase1 = 0.10

    # Anneal the limits based on best agents from phase 0?
    anneal-after-phase0 = True

    # Anneal during phase 1? Note that annealing during phase 1 is different from how it is
    # implemented in phase 0. During phase 1 (if annealing is on), we zero the limits
    # on all muscles except the laryngeal group (which is either randomized or pretrained from phase 0),
    # and the jaw group. We then let the algorithm explore for some number of steps, before we
    # anneal the jaw group and move on to opening up the lingual group. Then we anneal the lingual
    # group and we open up the labial group.
    anneal-during-phase1 = True

    # What crossover function should we use during phase0?
    crossover-function-phase0 = None

    # What crossover function should we use during phase1?
    crossover-function-phase1 = None

    # Pretraining output directory - this is just used for IPC; the artifacts are saved to the analysis directory
    pretraining-output-directory = /home/max/repos/ArtieInfant/Artie/tmpresults/pretraining

    # Training output directory - this is just used for IPC; the artifacts are saved to the analysis directory
    training-output-directory = /home/max/repos/ArtieInfant/Artie/tmpresults/training

    # Can be either 'xcor' or 'euclid' currently. Specifies the fitness function to use for mimicking.
    # XCorrelation does not use the autoencoder; euclid does.
    fitness-function = euclid

    # Targets to learn to mimic. Can be either a list of fpaths (which must each be in the test split) or a single integer,
    # in which case that many random fpaths are drawn from the test split.
    mimicry-targets = /home/max/Dropbox/thesis/harddrive_backup/filterbank_images/test_set/useless_subdirectory/english_14534.wav_10.png
                      /home/max/Dropbox/thesis/harddrive_backup/filterbank_images/test_set/useless_subdirectory/english_13313.wav_23.png

# The Preprocessing section contains all the configuration options for
# the preprocessing pipeline. This pipeline attempts to take completely raw
# WAV files and get them into shape for the RL and VAE algorithms.
[preprocessing]
    # -- Spectrograms --

    # The width of the samples in bytes
    bytewidth = 2

    # Number of channels to resample into. Only mono makes any sense for this experiment.
    nchannels = 1

    # Sample rate (in Hz) to resample to before creating the spectrograms
    spectrogram_sample_rate_hz = 8000.0

    # Seconds per spectrogram (this should almost certainly be the same value as phoneme-durations-ms)
    seconds_per_spectrogram = 0.3

    # Length (in seconds) of each spectrogram window
    spectrogram_window_length_s = 0.02

    # Fraction of overlap between each spectrogram window
    spectrogram_window_overlap = 0.2

    # Were to put the wav files that we used to create the spectrograms
    folder_to_save_wavs = /media/max/seagate8TB/thesis_audio/filterbank_audio/thesis2/

# The autoencoder section contains all the configuration options for the
# variational autoencoder portions of the experiment.
[autoencoder]
    # The input shape that the encoder layer is expecting. This will depend on the ms per spectrogram,
    # the overlap, and the sampling frequency of the audio.
    input_shape = 81 18 1

    # The dimensionality of the embedding space
    nembedding_dims = 3

    # The Keras Optimizer to use for the autoencoder
    optimizer = adadelta

    # The loss function to use for the autoencoder. See the VAE for available values.
    loss = mse

    # Value between 0 and 1.0 that shows how much of the whole VAE loss function to assign to KL loss
    kl_loss_proportion = 0.5

    # Value between 0 and 1.0 that shows how much of the whole VAE loss function to assign to reconstructive loss
    reconstructive_loss_proportion = 0.5

    # Value between 0 and 1.0 that shows how much of the whole VAE loss function to assign to the variance portion
    std_loss_proportion = 0.0

    # The root of the preprocessed data directory. We will grab data from here and feed it into the autoencoder to train it.
    preprocessed_data_root = /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/thousand

    # Test split that the autoencoder has not seen before. Used to create embeddings that will serve as targets for the synthesizer.
    testsplit_root = /home/max/Dropbox/thesis/harddrive_backup/filterbank_images/test_set/useless_subdirectory

    # The number of spectrograms to batch at a time
    batchsize = 32

    # The number of workers to use to train
    nworkers = 4

    # The number of epochs to train. Note that we define how long an epoch is manually.
    nepochs = 1000

    # The number of steps per epoch. (Should be num_samples / batchsize)
    steps_per_epoch = 30

    # The path to the weights to load
    weights_path = /home/max/repos/ArtieInfant/Artie/models/vae/test/latentdims-3D-vanilla-mse-10000data-50ep-81sp.h5

    # Save a before/after image after every epoch if True.
    visualize = False

    # Whether or not we should visualize the autoencoder with TensorBoard. If so, this must be a valid directory.
    tbdir = /home/max/repos/ArtieInfant/Artie/tensorboarddir

    # Analyze these spectrograms by running them through the autoencoder and comparing them side-by-side (and giving a reconstruction loss)
    spectrograms_to_reconstruct = /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/test_set/useless_subdirectory/english_30.wav_22.png
                                  /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/test_set/useless_subdirectory/english_129.wav_26.png
                                  /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/test_set/useless_subdirectory/english_14480.wav_4.png
                                  /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/test_set/useless_subdirectory/english_14705.wav_19.png
                                  /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/test_set/useless_subdirectory/english_8874.wav_12.png
                                  /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/test_set/useless_subdirectory/english_8877.wav_21.png
                                  /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/thousand/useless_subdirectory/english_11100.wav_35.png
                                  /home/max/Dropbox/thesis/harddrive_backup/test_spectrogram_images/thousand/useless_subdirectory/english_843.wav_1.png

    # Plot a topographic analysis of the latent space from (low, low) to (high, high) (for 2D).
    topographic_swathe_low = -1.0

    # Plot a topographic analysis of the latent space from (low, low) to (high, high) (for 2D).
    topographic_swathe_high = 1.0

    # Is this a variational autoencoder?
    is_variational = False

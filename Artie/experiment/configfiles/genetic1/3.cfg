[experiment]
    # Name of the experiment
    name = geneticI-0.5s-tps0.0-0.2-0.4-100pop-50gen-rms-nox

    # A directory where results will be saved will be created from joining this root directory to the name of the experiment
    save_root = /home/max/Dropbox/thesis/results/real

    # Random seed for the experiment (must be 32-bit unsigned integer)
    random-seed = 235238

# The Synthesizer section contains all the configuration options for the
# Articulatory Synthesis portions of the experiment.
[synthesizer]
    # The number of ms of all phonemes we will try to learn.
    phoneme-durations-ms = 500

    # When during the articulation the controller may change muscle activations.
    articulation-time-points-ms = 0.0 0.2 0.4

    # These are the [min, max, min, max] values for each articulator
    # for each time point. See synthesizer.py for which of these are in which
    # articulator group.
    # This matrix specifies the total limits. If annealing is turned on,
    # we zero out portions of the matrix during specific portions of phase 1
    # training. Regardless of whether annealing is on or off for phase 0,
    # we zero out all but the laryngeal group during phase 0.
    allowed-articulator-values = {
        Lungs:                      [0.2  0.2   0.0  0.0   0.0  0.0],
        Interarytenoid:             [0.5  0.5   0.5  0.5   0.5  0.5],
        # This muscle changes the pitch (frequency)
        Cricothyroid:               [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        # This and thyroarytenoid work together to do something I guess
        Vocalis:                    [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        Thyroarytenoid:             [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        # These two have to do with breathing maybe?
        PosteriorCricoarytenoid:    [0.0  0.0   0.0  0.0   0.0  0.0],
        LateralCricoarytenoid:      [0.0  0.0   0.0  0.0   0.0  0.0],
        # Group of muscles used in swallowing. Less so in speech. Set to zeros.
        Stylohyoid:                 [0.0  0.0   0.0  0.0   0.0  0.0],
        Thyropharyngeus:            [0.0  0.0   0.0  0.0   0.0  0.0],
        LowerConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0],
        MiddleConstrictor:          [0.0  0.0   0.0  0.0   0.0  0.0],
        UpperConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0],
        Sphincter:                  [0.0  0.0   0.0  0.0   0.0  0.0],
        # Helps with tongue (all glossus muscles)
        Hyoglossus:                 [0.0  0.0   0.0  0.0   0.0  0.0],
        Styloglossus:               [0.0  0.5   0.0  0.5   0.0  0.5],
        Genioglossus:               [0.0  0.0   0.0  0.0   0.0  0.0],
        # Tongue!
        UpperTongue:                [-1.0  0.0   -1.0  0.0   -1.0  0.0],
        LowerTongue:                [-1.0  0.0   -1.0  0.0   -1.0  0.0],
        TransverseTongue:           [0.0  0.0   0.0  0.0   0.0  0.0],
        VerticalTongue:             [0.0  0.0   0.0  0.0   0.0  0.0],
        # Helpful for smiling
        Risorius:                   [0.0  0.0   0.0  0.0   0.0  0.0],
        # Lip-puckering
        OrbicularisOris:            [0.5  1.0   0.5  1.0   0.5  1.0],
        # Soft-palate (responsible for nasalisation) - same with tensor palatini
        LevatorPalatini:            [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        TensorPalatini:             [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        # Helps to open/close the jaw
        Masseter:                   [-0.5  0.0   -0.5  0.0   -0.5  0.0],
        # Important for moving the bottom of the mouth and the tongue
        Mylohyoid:                  [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        # Helps to open/close the jaw
        LateralPterygoid:           [0.0  0.0   0.0  0.0   0.0  0.0],
        # Helpful in puckering and whistling
        Buccinator:                 [0.0  0.0   0.0  0.0   0.0  0.0],
        }

    # The number of agents to create as part of the genetic algorithm for phase 0 (loudness training)
    nagents-phase0 = 100

    # The number of agents to create as part of the genetic algorithm for phase 1 (mimicking)
    nagents-phase1 = 0

    # The number of workers to use in parallel for training the genetic algorithm in phase 0
    nworkers-phase0 = 12

    # The number of workers to use in parallel for training the genetic algorithm in phase 1
    nworkers-phase1 = 12

    # The number of generations of agents to simulate for the genetic algorithm in phase 0. Can be None.
    # Either this or fitness-target-phase0 must be specified, however.
    niterations-phase0 = 50

    # The number of generations of agents to simulate for the genetic algorithm in phase 1. Can be None.
    # Either this or fitness-target-phase1 must be specified, however.
    # If anneal-during-phase1 is True, this can be a list, in which case, it should contain the number
    # of iterations for each group of articulators. If annealing is turned on and this is not a list,
    # we will do this many iterations per anneal.
    # Jaw, Nasal, Lingual support, Lingual main, Labial
    niterations-phase1 = 0

    # The target fitness value to converge on in the genetic algorithm in phase 0. Can be None.
    # Either this or niterations-phase0 must be specified, however.
    fitness-target-phase0 = None

    # The target fitness value to converge on in the genetic algorithm in phase 1. Can be None.
    # Either this or niterations-phase1 must be specified, however.
    # If anneal-during-phase1 is True, this can be a list, in which case, it should contain the fitness targets
    # for each group of articulators. If annealing is turned on and this is not a list,
    # we will use this for each articulator group.
    fitness-target-phase1 = None

    # The top x percent of each generation is chosen for breeding in the genetic algorithm
    fraction-of-generation-to-select-phase0 = 0.5

    # The top x percent of each generation is chosen for breeding in the genetic algorithm
    fraction-of-generation-to-select-phase1 = 0.5

    # X percent of each generation is subject to mutation.
    fraction-of-generation-to-mutate-phase0 = 0.10

    # X percent of each generation is subject to mutation.
    fraction-of-generation-to-mutate-phase1 = 0.10

    # Anneal the limits based on best agents from phase 0?
    anneal-after-phase0 = True

    # Anneal during phase 1? Note that annealing during phase 1 is different from how it is
    # implemented in phase 0. During phase 1 (if annealing is on), we zero the limits
    # on all muscles except the laryngeal group (which is either randomized or pretrained from phase 0),
    # and the jaw group. We then let the algorithm explore for some number of steps, before we
    # anneal the jaw group and move on to opening up the lingual group. Then we anneal the lingual
    # group and we open up the labial group.
    anneal-during-phase1 = True

    # What crossover function should we use during phase0?
    crossover-function-phase0 = None

    # What crossover function should we use during phase1?
    crossover-function-phase1 = None

    # Pretraining output directory - this is just used for IPC; the artifacts are saved to the analysis directory
    pretraining-output-directory = /home/max/repos/ArtieInfant/Artie/tmpresults/pretraining

    # Training output directory - this is just used for IPC; the artifacts are saved to the analysis directory
    training-output-directory = /home/max/repos/ArtieInfant/Artie/tmpresults/training

# The Preprocessing section contains all the configuration options for
# the preprocessing pipeline. This pipeline attempts to take completely raw
# WAV files and get them into shape for the RL and VAE algorithms.
[preprocessing]
    # -- Spectrograms --

    # The width of the samples in bytes
    bytewidth = 2

    # Sample rate (in Hz) to resample to before creating the spectrograms
    spectrogram_sample_rate_hz = 16000.0

    # Seconds per spectrogram (this should almost certainly be the same value as phoneme-durations-ms)
    seconds_per_spectrogram = 0.5

    # Length (in seconds) of each spectrogram window
    spectrogram_window_length_s = 0.03

    # Fraction of overlap between each spectrogram window
    spectrogram_window_overlap = 0.2

###### DUMMY AUTOENCODER SECTION : NOT USED IN THIS EXPERIMENT #########
# The autoencoder section contains all the configuration options for the
# variational autoencoder portions of the experiment.
[autoencoder]
    # The input shape that the encoder layer is expecting. This will depend on the ms per spectrogram,
    # the overlap, and the sampling frequency of the audio.
    input_shape = 81 18 1

    # The dimensionality of the embedding space
    nembedding_dims = 2

    # The Keras Optimizer to use for the autoencoder
    optimizer = adadelta

    # The loss function to use for the autoencoder. See the VAE for available values.
    loss = mse

    # Value between 0 and 1.0 that shows how much of the whole VAE loss function to assign to KL loss
    kl_loss_proportion = 0.5

    # Value between 0 and 1.0 that shows how much of the whole VAE loss function to assign to reconstructive loss
    reconstructive_loss_proportion = 0.5

    # Value between 0 and 1.0 that shows how much of the whole VAE loss function to assign to the variance portion
    std_loss_proportion = 0.0

    # The root of the preprocessed data directory. We will grab data from here and feed it into the autoencoder to train it.
    preprocessed_data_root = /media/max/seagate8TB/thesis_audio/filterbank_images/ten

    # Test split that the autoencoder has not seen before. Used to create embeddings that will serve as targets for the synthesizer.
    testsplit_root = /media/max/seagate8TB/thesis_audio/filterbank_images/test_set/useless_subdirectory

    # The number of spectrograms to batch at a time
    batchsize = 2

    # The number of workers to use to train
    nworkers = 2

    # The number of epochs to train. Note that we define how long an epoch is manually.
    nepochs = 5000

    # The number of steps per epoch. (Should be num_samples / batchsize)
    steps_per_epoch = 5

    # The directory to save the weights
    weights_path = /home/max/repos/ArtieInfant/Artie/models/vae/

    # Save a before/after image after every epoch if True.
    visualize = False

    # Whether or not we should visualize the autoencoder with TensorBoard. If so, this must be a valid directory.
    tbdir = /home/max/repos/ArtieInfant/Artie/tensorboarddir

    # Analyze these spectrograms by running them through the autoencoder and comparing them side-by-side (and giving a reconstruction loss)
    spectrograms_to_reconstruct = /media/max/seagate8TB/thesis_audio/filterbank_images/test_set/useless_subdirectory/english_265.wav_25.png
                                  /media/max/seagate8TB/thesis_audio/filterbank_images/test_set/useless_subdirectory/english_3163.wav_49.png
                                  /media/max/seagate8TB/thesis_audio/filterbank_images/test_set/useless_subdirectory/english_7736.wav_21.png
                                  /media/max/seagate8TB/thesis_audio/filterbank_images/test_set/useless_subdirectory/english_10711.wav_29.png
                                  /media/max/seagate8TB/thesis_audio/filterbank_images/test_set/useless_subdirectory/english_13489.wav_1.png
                                  /media/max/seagate8TB/thesis_audio/filterbank_images/test_set/useless_subdirectory/english_17543.wav_30.png
                                  /media/max/seagate8TB/thesis_audio/filterbank_images/ten/useless_subdirectory/english_1691.wav_0.png
                                  /media/max/seagate8TB/thesis_audio/filterbank_images/ten/useless_subdirectory/english_1691.wav_32.png

    # Plot a topographic analysis of the latent space from (low, low) to (high, high) (for 2D).
    topographic_swathe_low = -1.0

    # Plot a topographic analysis of the latent space from (low, low) to (high, high) (for 2D).
    topographic_swathe_high = 1.0

    # Is this a variational autoencoder?
    is_variational = True

# This configuration file contains all the same configurations as the
# Thesis experiment, but the values are suitable for unittesting quickly.

[experiment]
    # Name of the experiment
    name = debug-experiment

    # Directory to save the artifacts
    save_root = /home/maxst/repos/ArtieInfant/Artie/debugdata/results

    # Random seed for the experiment (must be 32-bit unsigned integer)
    random-seed = 235238

# The Synthesizer section contains all the configuration options for the
# Articulatory Synthesis portions of the experiment.
[synthesizer]
    # The number of ms of all phonemes we will try to learn.
    phoneme-durations-ms = 500

    # When during the articulation the controller may change muscle activations.
    articulation-time-points-ms = 0 200 400

    # These are the [min, max, min, max, min, max] values for each articulator
    # for each time point.
    ####### THESE VALUES CREATE A KNOWN SOUND (when articulation-time-points-ms is 0, 100, 250, 500) #######
    #allowed-articulator-values = {
    #    Lungs:                      [0.2  0.2   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Interarytenoid:             [0.5  0.5   0.5  0.5   0.5  0.5   0.5  0.5],
    #    Cricothyroid:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Vocalis:                    [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Thyroarytenoid:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    PosteriorCricoarytenoid:    [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LateralCricoarytenoid:      [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Stylohyoid:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Thyropharyngeus:            [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LowerConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    MiddleConstrictor:          [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    UpperConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Sphincter:                  [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Hyoglossus:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Styloglossus:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Genioglossus:               [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    UpperTongue:                [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LowerTongue:                [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    TransverseTongue:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    VerticalTongue:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Risorius:                   [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    OrbicularisOris:            [0.0  0.0   0.0  0.0   0.2  0.2   0.0  0.0],
    #    LevatorPalatini:            [1.0  1.0   1.0  1.0   1.0  1.0   1.0  1.0],
    #    TensorPalatini:             [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Masseter:                   [0.0  0.0   0.0  0.0   0.7  0.7   0.0  0.0],
    #    Mylohyoid:                  [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    LateralPterygoid:           [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    Buccinator:                 [0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0],
    #    }

    # These are the [min, max, min, max] values for each articulator
    # for each time point. See synthesizer.py for which of these are in which
    # articulator group.
    # This matrix specifies the total limits. If annealing is turned on,
    # we zero out portions of the matrix during specific portions of phase 1
    # training. Regardless of whether annealing is on or off for phase 0,
    # we zero out all but the laryngeal group during phase 0.
    allowed-articulator-values = {
        Lungs:                      [0.2  0.2   0.0  0.0   0.0  0.0],
        Interarytenoid:             [0.5  0.5   0.5  0.5   0.5  0.5],
        # This muscle changes the pitch (frequency)
        Cricothyroid:               [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        # This and thyroarytenoid work together to do something I guess
        Vocalis:                    [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        Thyroarytenoid:             [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        # These two have to do with breathing maybe?
        PosteriorCricoarytenoid:    [0.0  0.0   0.0  0.0   0.0  0.0],
        LateralCricoarytenoid:      [0.0  0.0   0.0  0.0   0.0  0.0],
        # Group of muscles used in swallowing. Less so in speech. Set to zeros.
        Stylohyoid:                 [0.0  0.0   0.0  0.0   0.0  0.0],
        Thyropharyngeus:            [0.0  0.0   0.0  0.0   0.0  0.0],
        LowerConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0],
        MiddleConstrictor:          [0.0  0.0   0.0  0.0   0.0  0.0],
        UpperConstrictor:           [0.0  0.0   0.0  0.0   0.0  0.0],
        Sphincter:                  [0.0  0.0   0.0  0.0   0.0  0.0],
        # Helps with tongue (all glossus muscles)
        Hyoglossus:                 [0.0  0.0   0.0  0.0   0.0  0.0],
        Styloglossus:               [0.0  0.5   0.0  0.5   0.0  0.5],
        Genioglossus:               [0.0  0.0   0.0  0.0   0.0  0.0],
        # Tongue!
        UpperTongue:                [-1.0  0.0   -1.0  0.0   -1.0  0.0],
        LowerTongue:                [-1.0  0.0   -1.0  0.0   -1.0  0.0],
        TransverseTongue:           [0.0  0.0   0.0  0.0   0.0  0.0],
        VerticalTongue:             [0.0  0.0   0.0  0.0   0.0  0.0],
        # Helpful for smiling
        Risorius:                   [0.0  0.0   0.0  0.0   0.0  0.0],
        # Lip-puckering
        OrbicularisOris:            [0.5  1.0   0.5  1.0   0.5  1.0],
        # Soft-palate (responsible for nasalisation) - same with tensor palatini
        LevatorPalatini:            [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        TensorPalatini:             [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        # Helps to open/close the jaw
        Masseter:                   [-0.5  0.0   -0.5  0.0   -0.5  0.0],
        # Important for moving the bottom of the mouth and the tongue
        Mylohyoid:                  [-1.0  1.0   -1.0  1.0   -1.0  1.0],
        # Helps to open/close the jaw
        LateralPterygoid:           [0.0  0.0   0.0  0.0   0.0  0.0],
        # Helpful in puckering and whistling
        Buccinator:                 [0.0  0.0   0.0  0.0   0.0  0.0],
        }

    # The number of agents to create as part of the genetic algorithm for phase 0 (loudness training)
    nagents-phase0 = 10

    # The number of agents to create as part of the genetic algorithm for phase 1 (mimicking)
    nagents-phase1 = 10

    # The number of workers to use in parallel for training the genetic algorithm in phase 0
    nworkers-phase0 = 12

    # The number of workers to use in parallel for training the genetic algorithm in phase 1
    nworkers-phase1 = 12

    # The number of generations of agents to simulate for the genetic algorithm in phase 0. Can be None.
    # Either this or fitness-target-phase0 must be specified, however.
    niterations-phase0 = 1

    # The number of generations of agents to simulate for the genetic algorithm in phase 1. Can be None.
    # Either this or fitness-target-phase1 must be specified, however.
    # If anneal-during-phase1 is True, this can be a list, in which case, it should contain the number
    # of iterations for each group of articulators. If annealing is turned on and this is not a list,
    # we will do this many iterations per anneal.
    # Jaw, Nasal, Lingual support, Lingual main, Labial
    niterations-phase1 = 1 1 1 1 1

    # The target fitness value to converge on in the genetic algorithm in phase 0. Can be None.
    # Either this or niterations-phase0 must be specified, however.
    fitness-target-phase0 = None

    # The target fitness value to converge on in the genetic algorithm in phase 1. Can be None.
    # Either this or niterations-phase1 must be specified, however.
    # If anneal-during-phase1 is True, this can be a list, in which case, it should contain the fitness targets
    # for each group of articulators. If annealing is turned on and this is not a list,
    # we will use this for each articulator group.
    fitness-target-phase1 = None

    # The top x percent of each generation is chosen for breeding in the genetic algorithm
    fraction-of-generation-to-select-phase0 = 0.5

    # The top x percent of each generation is chosen for breeding in the genetic algorithm
    fraction-of-generation-to-select-phase1 = 0.5

    # X percent of each generation is subject to mutation.
    fraction-of-generation-to-mutate-phase0 = 0.10

    # X percent of each generation is subject to mutation.
    fraction-of-generation-to-mutate-phase1 = 0.10

    # Anneal the limits based on best agents from phase 0?
    anneal-after-phase0 = True

    # Anneal during phase 1? Note that annealing during phase 1 is different from how it is
    # implemented in phase 0. During phase 1 (if annealing is on), we zero the limits
    # on all muscles except the laryngeal group (which is either randomized or pretrained from phase 0),
    # and the jaw group. We then let the algorithm explore for some number of steps, before we
    # anneal the jaw group and move on to opening up the lingual group. Then we anneal the lingual
    # group and we open up the labial group.
    anneal-during-phase1 = True

    # What crossover function should we use during phase0?
    crossover-function-phase0 = None

    # What crossover function should we use during phase1?
    crossover-function-phase1 = None

    # Pretraining output directory - this is just used for IPC; the artifacts are saved to the analysis directory
    pretraining-output-directory = /home/maxst/repos/ArtieInfant/Artie/tmpresults/pretraining

    # Training output directory - this is just used for IPC; the artifacts are saved to the analysis directory
    training-output-directory = /home/maxst/repos/ArtieInfant/Artie/tmpresults/training

    # Can be either 'xcor' or 'euclid' currently. Specifies the fitness function to use for mimicking.
    # XCorrelation does not use the autoencoder; euclid does.
    fitness-function = euclid

    # Targets to learn to mimic. Can be either a list of fpaths (which must each be in the test split) or a single integer,
    # in which case that many random fpaths are drawn from the test split.
    mimicry-targets = 1

# The autoencoder section contains all the configuration options for the
# variational autoencoder portions of the experiment.
[autoencoder]
    # The input shape that the encoder layer is expecting. This will depend on the ms per spectrogram,
    # the overlap, and the sampling frequency of the audio.
    input_shape = 241 20 1

    # The dimensionality of the embedding space
    nembedding_dims = 2

    # The Keras Optimizer to use for the autoencoder
    optimizer = adadelta

    # The loss function to use for the autoencoder. See the VAE for available values.
    loss = mse

    # The root of the preprocessed data directory. We will grab data from here and feed it into the autoencoder to train it.
    preprocessed_data_root = /media/maxst/repos/ArtieInfant/Artie/debugdata/

    # Test split that the autoencoder has not seen before. Used to create embeddings that will serve as targets for the synthesizer.
    testsplit_root = /media/maxst/repos/ArtieInfant/Artie/debugdata/useless_subdirectory

    # The number of spectrograms to batch at a time
    batchsize = 2

    # The number of workers to use to train
    nworkers = 2

    # The number of epochs to train. Note that we define how long an epoch is manually.
    nepochs = 10

    # The number of steps per epoch. (Should be num_samples / batchsize)
    steps_per_epoch = 5

    # The path to save/load the autoencoder weights. A timestamp and .h5 extension will be appended to this base name.
    weights_path = /home/maxst/repos/ArtieInfant/Artie/models/vae/

    # Save a before/after image after every epoch if True.
    visualize = False

    # Whether or not we should visualize the autoencoder with TensorBoard. If so, this must be a valid directory.
    tbdir = /home/maxst/repos/ArtieInfant/Artie/tensorboarddir

    # Analyze these spectrograms by running them through the autoencoder and comparing them side-by-side (and giving a reconstruction loss)
    spectrograms_to_reconstruct = /home/maxst/repos/ArtieInfant/Artie/debugdata/useless_subdirectory/english_8292.wav_2.png
                                  /home/maxst/repos/ArtieInfant/Artie/debugdata/useless_subdirectory/english_7552.wav_33.png

# The Preprocessing section contains all the configuration options for
# the preprocessing pipeline. This pipeline attempts to take completely raw
# WAV files and get them into shape for the RL and VAE algorithms.
[preprocessing]
    # Number of channels to resample into. Only mono makes any sense for this experiment.
    nchannels = 1

    # Bytewidth of each sample to resample to.
    bytewidth = 2

    # -- Spectrograms --

    # Were to put the wav files that we used to create the spectrograms
    folder_to_save_wavs = /media/max/seagate8TB/thesis_audio/filterbank_audio/all/

    # Use a filterbank?
    use_filterbank = False

    # Sample rate (in Hz) to resample to before creating the spectrograms
    spectrogram_sample_rate_hz = 16000.0

    # Seconds per spectrogram (this should almost certainly be the same value as phoneme-durations-ms)
    seconds_per_spectrogram = 0.5

    # Length (in seconds) of each spectrogram window
    spectrogram_window_length_s = 0.03

    # Fraction of overlap between each spectrogram window
    spectrogram_window_overlap = 0.2
